{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Data-Driven Approach to Job Discrimination Law\n",
    "## CS481 Assignment 1: \n",
    "### Milestone 2: Building a compliant algorithmic hiring system...\n",
    "\n",
    "In the last milestone, you became well acquainted with Sprawlmart’s latest dataset of candidates and a few algorithmic methods for evaluating the individuals based on their data points.  By interrogating their performance chiefly through the lens of the 4/5ths rule you determined that each of the techniques ran into non-insignificant litigatory risk of a disparate impact claim. Confident that your team of SLS-trained lawyers and Stanford Engineering team can minimize the risk, your team has decided to prototype its own algorithmic hiring system to give the HR team a better sense of how to develop a hiring pipeline that can still take advantage of advances in machine learning while also prioritizing the importance of unbiased assessments, protecting the firm from expensive and damaging lawsuits.\n",
    "\n",
    "\n",
    "Milestone Outline:\n",
    "* Feature selection\n",
    "* Model selection \n",
    "* Model training & evaluation\n",
    "* Justifying your approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* First, strategically choose the subset of features you’d like to include in your model.  (In your writeup)\n",
    "\n",
    "* Did you select any protected characteristics as features to include in your model?  If so, why? What legal claims, frivolous or substantial, might you face due to their inclusion?  How would you respond?  (in your writeup)\n",
    "\n",
    "* Explain the process or standard by which you selected each field to include in your feature set.  (e.g. you ran a regression to determine feature importance, you picked those fields that were most intuitive to you, etc.). Why might this process be important in defending a claim against disparate impact? (in your writeup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ---- Setup the features and dataset here ------ ####\n",
    "def featureSelector(candidates_df):\n",
    "    ###### ----------  BEGIN FEATURE SELECTION HERE ----- ####\n",
    "\n",
    "\n",
    "    ##### -----------  END FEATURE SELECTION HERE ------- #####\n",
    "candidates_info = featureSelector(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a Model\n",
    "* Detail the model specifications you've planned out.  Describe its architecture and how it arrives at decisions on each candidate in detail.  Your description should be rigorous yet simple enough for a non-technical law student to understand.  \n",
    "\n",
    "* Build your model that you've laid out in part (a)! Again, you are free to make use of the algorithms and code provided to you in the first milestone. Noting the \"build\" command can be shocking - for those of you new to this, this really might just mean making some new \"model\" employees with different set values for their datafields, and playing around with the way you calculate distance between the model candidates - looking into different distance metrics (L1 vs. L2) on distance.  For those of you comfortable - go all in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ---- Setup your model and dataset here - no need to use this template ------ ####\n",
    "class compliantAlgorithmicModel():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, features, labels):\n",
    "    \n",
    "    \n",
    "    \n",
    "    def predict(self, features):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ok, now provide a breakdown of the candidates that were selected by your algorithm to move on. What was the breakdown of candidates chosen based on protected characteristics?  Does your algorithm pass the sniff test?  If not you'll have to go back and debug your model.  (Some common things to look for, does it seem to be just making blanket classifications - e.g. everyone is unqualified, or everyone is excellent, or all those with cultural fit are selected, etc.). Do the data points of the selected candidates match what you engineered your algorithm to optimize for? Note some outliers in your pool of selected candidates.\n",
    "\n",
    "\n",
    "* Evaluate your prototype’s performance with relation to the 4/5ths rule. You can use the code below to perform your analysis. Is it compliant among all protected characteristics?\n",
    "\n",
    "* Given your algorithm’s architecture and features utilized, does employing it create a risk for the company being liable under a disparate treatment claim? Explain your answer.\n",
    "\n",
    "* If your algorithm does not comply with the 4/5ths rule, please explain how you would make a defense of its employment, if you were to encounter a claim of disparate impact?  Are you able to forge a case of business necessity? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --------------- RUN YOUR MODEL ON THE CANDIDATES ------------- ###\n",
    "    # Start Code\n",
    "    \n",
    "    \n",
    "    \n",
    "    # End Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --------------- Evaluate your model's selections ------------- ###\n",
    "    # Start Code\n",
    "    \n",
    "    \n",
    "    \n",
    "    # End Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Performance:\n",
    "\"From the module casebook\" - The folks from HR Engineering actually turned out to have an additional dataset of about 250 past/current employees with the same datapoints you encountered previously, how fortunate! Noting the importance of minimizing potential bias, the dataset was constructed to be diverse and well-balanced. Moreover, they also have a field marking the quality of each candidate’s performance during their most recent year of employment for Sprawlmart.  Employees were labeled as either satisfactory or unsatisfactory.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --------------- Loading the \"Held-Out\" Dataset ------------- ###\n",
    "employeeData = loadModel(\"../data/employeeData.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run your algorithm on this dataset with the satisfactory/unsatisfactory data field left out. You should now have a bunch of candidates “selected” from this dataset.  \n",
    "\n",
    "* Now again, analyze your algorithm’s compliance to the 4/5ths rule.  You’ve already addressed the disparate treatment claim above so you should focus on disparate impact for the new dataset. If this were the dataset of candidates you were evaluating, would there now be a possible disparate impact claim?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --------------- Run your model to produce predictions ------------- ###\n",
    "compliantHiringAlg = compliantHiringAlg()\n",
    "compliantHiringAlg.predict(employee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --------------- Evaluate your model's 4/5th status ------------- ###\n",
    "    # Start Code\n",
    "    \n",
    "    \n",
    "    \n",
    "    # End Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, how accurate is your algorithm with respect to selecting candidates that actually performed satisfactorily?  How many false positives did you have - employees your algorithm selected that actually exhibited unsatisfactory performance? How many false negatives did you have - employees your algorithm did not select but actually had satisfactory performance?\n",
    "\n",
    "* Using those calculations and the formulas below, calculate the precision and recall rates of your algorithm on this “held-out” dataset.   Intuitively, what does your precision and recall rate tell you about the performance of your algorithm on this dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcAccuracy():\n",
    "    # Start Code\n",
    "    \n",
    "    # End Code\n",
    "\n",
    "def countNumFalsePositives():\n",
    "    # Start Code\n",
    "    \n",
    "    # End Code\n",
    "    \n",
    "def countNumFalseNegatives():\n",
    "    # Start Code\n",
    "    \n",
    "    # End Code\n",
    "\n",
    "def calcRecall():\n",
    "    # Start Code\n",
    "    # TP / (TP + FN)\n",
    "    # End Code\n",
    "    \n",
    "def calcPrecision():\n",
    "    # Start Code\n",
    "    # TP / (TP + FP)\n",
    "    # End Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration\n",
    "\n",
    "* Implement the improvements you proposed.  Analyze your performance again under accuracy with our “held-out” dataset as well as 4/5ths compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### - Implement Model Improvements for Disparate Impact - ####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Recall from the casebook - \"Using what you have learned in class, and the readings assigned, suggest three to five substantial adjustments you can make to improve your algorithm’s performance.\"\n",
    "\n",
    "* Implement two of them and test your performance.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### - Implement Model Improvements for Performance Metrics - ####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Did those changes affect your compliance to the 4/5ths rule at all?\n",
    "\n",
    "* Finally using the formulas below, report your model’s adherence to statistical parity, and differential validity on this held-out dataset. What do these results tell you?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### - Evaluate for 4/5ths compliance - ####\n",
    "\n",
    "\n",
    "#### - Evaluate for fairness metrics - ####\n",
    "\n",
    "def calcStatisticalParity():\n",
    "    # Start Code\n",
    "    # End Code\n",
    "\n",
    "def calcDifferentialValidity():\n",
    "    # Start Code\n",
    "    # End Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-6a6385f2efc2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-6a6385f2efc2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Additional Legal Issues or Places for Integration\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Additional Legal Issues or Places for Integration\n",
    "On Disparate Impact:\n",
    "1. What constitutes a protected group? ==> initially it may just be black or white but what about\n",
    "black female selection rate versus white male selection rate. E.g. our black selection rate is \n",
    "good, our female selection rate is solid, but we practically reject every black female. \n",
    "2. At what stage do we consider 4/5ths discrimination, at screening, interviewing, hiring?\n",
    "3. Besides, the selection rate, what other metrics can be used as additional evidence during litigation \n",
    "to prove or disprove disparate impact.\n",
    "\n",
    "\n",
    "On Disparate Treatment:\n",
    "1. How could an algorithm produce a \"legitimate non-discriminatory reason\" for which the similarly\n",
    "situated individual was rejected. \n",
    "2. This begins to implicate plans for affirmative action ... we see that the algorithm is potentially\n",
    "acting in a discriminatory manner. We have two options at the teams... we can\n",
    "\n",
    "1. Intervene with human decision-making after the algorithm spits out scores/selections\n",
    "2. Intervene by fundamentally changing the model's architecture - e.g. we implement a fairness\n",
    "correcting measure etc.  \n",
    "    - This opens a wide span of options in that there are so many ways in which we can tweak architecture\n",
    "        - Begs the question as to whether there ought to be standardized procedure for tweaking the architecture?\n",
    "        - Would that be valuable to companies to avoid litigation risk - a kind of safe harbor....\n",
    "    - Key question - What is the existing case law on this - here is where we introduce to the Ricci v Weber\n",
    "    Distinction\n",
    "\n",
    "On the ADA: \n",
    "- You have voice\n",
    "- WHat would an alternative route of interviewing look like for someone who requests it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
