{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from scipy.linalg import eigh, cholesky\n",
    "from scipy.stats import norm\n",
    "from pylab import plot, show, axis, subplot, xlabel, ylabel, grid\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphSelectionRates(selected, candidates, protectedClass):\n",
    "    selected_candidates = selected.copy()\n",
    "    candidates_all = candidates.copy()\n",
    "    raceIndxs = {\"Caucasian\": 0, \"African-American\": 1, \"Asian\": 2, \"Hispanic\": 3, \"Other\": 4 }\n",
    "    sexIndxs = {\"Male\":0, \"Female\":1}\n",
    "    \n",
    "    if protectedClass == \"race\":\n",
    "        features = [col for col in selected_candidates if col.startswith(\"race_\")]\n",
    "        race_selected = selected_candidates[features].idxmax(axis=1).str.replace('race_', '')\n",
    "        race_all = candidates_all[features].idxmax(axis=1).str.replace('race_', '')\n",
    "        \n",
    "        candidates_all[\"Race\"] = race_all\n",
    "        selected_candidates[\"Race\"] = race_selected\n",
    "\n",
    "        numCandidates = candidates_all[\"Race\"].value_counts()\n",
    "        numQualified = selected_candidates[\"Race\"].value_counts()\n",
    "\n",
    "        selectionRate1 = numQualified[\"Caucasian\"] / numCandidates[\"Caucasian\"]\n",
    "        selectionRate2 = numQualified[\"Asian\"] / numCandidates[\"Asian\"]\n",
    "        selectionRate3 = numQualified[\"African-American\"] / numCandidates[\"African-American\"]\n",
    "        selectionRate4 = numQualified[\"Hispanic\"] / numCandidates[\"Hispanic\"]\n",
    "        \n",
    "        print(\"The selection rate for \" + \"Caucasian\" + \"s: \",selectionRate1)\n",
    "        print(\"The selection rate for \" + \"Asian\" + \"s: \", selectionRate2)\n",
    "        print(\"The selection rate for \" + \"African-American\" + \"s: \",selectionRate3)\n",
    "        print(\"The selection rate for \" + \"Hispanic\" + \"s: \",selectionRate4)\n",
    "        \n",
    "        y_pos = np.arange(4)\n",
    "        performance = [selectionRate1, selectionRate2, selectionRate3, selectionRate4]\n",
    "        plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "        plt.xticks(y_pos, (\"Caucasian\", \"Asian\", \"African-American\", \"Hispanic\"))\n",
    "        plt.ylabel('Selection Rate')\n",
    "        plt.title('Selection Rate Comparisons by Race')\n",
    "        plt.show()\n",
    "    elif protectedClass == \"gender\":\n",
    "        \n",
    "        features = [col for col in selected_candidates if col.startswith(\"gender_\")]\n",
    "        gender_selected = selected_candidates[features].idxmax(axis=1).str.replace('gender_', '')\n",
    "        gender_all = candidates_all[features].idxmax(axis=1).str.replace('gender_', '')\n",
    "\n",
    "        candidates_all[\"Gender\"] = gender_all\n",
    "        selected_candidates[\"Gender\"] = gender_selected\n",
    "        \n",
    "        numCandidates = candidates_all[\"Gender\"].value_counts()\n",
    "        numQualified = selected_candidates[\"Gender\"].value_counts()\n",
    "        \n",
    "        print(numCandidates)\n",
    "        print(numQualified) \n",
    "        \n",
    "        maleSelectionRate = numQualified[\"male\"] / numCandidates[\"male\"]\n",
    "        femaleSelectionRate = numQualified[\"female\"] / numCandidates[\"female\"]\n",
    "        print(\"The selection rate for \" + \"Male\" + \"s: \", maleSelectionRate)\n",
    "        print(\"The selection rate for \" + \"Female\" + \"s: \", femaleSelectionRate)\n",
    "        y_pos = np.arange(2)\n",
    "        performance = [maleSelectionRate, femaleSelectionRate]\n",
    "        plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "        plt.xticks(y_pos, (\"Male\", \"Female\"))\n",
    "        plt.ylabel('Selection Rate')\n",
    "        plt.title('Selection Rate Comparisons by Sex')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Try another protected type - gender or race\")\n",
    "        \n",
    "        \n",
    "def getOnehottedDataset(dataset, features, prefixes):\n",
    "# race, sex, sports, birth origin, education, educational prestige, criminal record, arrest record,\n",
    "    onehotted_data = dataset.copy()\n",
    "    onehotted_data = pd.get_dummies(onehotted_data, columns=features, prefix=prefixes)\n",
    "    return onehotted_data\n",
    "\n",
    "        \n",
    "def classificationSelection(candidates, labels, acceptValue):\n",
    "    df = candidates.copy()\n",
    "    df[\"Labels\"] = labels\n",
    "    candidatesSelected = df[df[\"Labels\"].isin([acceptValue])]\n",
    "    return candidatesSelected\n",
    "\n",
    "def transformDatapointsToScale(candidates, selectedFeatures):\n",
    "    df = candidates.copy()\n",
    "    for feature in selectedFeatures:\n",
    "        maximum = df[feature].max()\n",
    "#         print(maximum)\n",
    "        df[feature] = df[feature].apply(lambda x: x / maximum)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # employees = pd.read_csv(\"./employeeData_male_African-American.csv\")\n",
    "# dfs = [pd.read_csv(\"./employeeData_male_African-American.csv\"),\n",
    "#        pd.read_csv(\"./employeeData_male_Caucasian.csv\"),\n",
    "#       ]\n",
    "# #        pd.read_csv(\"./employeeData_female_African-American.csv\")]\n",
    "# employees = pd.concat(dfs)\n",
    "employees = pd.read_csv(\"employees_milestone2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "-2    2000\n",
      "-1    2000\n",
      " 0    2000\n",
      " 1    2000\n",
      " 2    2000\n",
      "dtype: int64\n",
      "{2: 1673, 1: 1372, -1: 1576, 0: 1218, -2: 1661}\n",
      "The accuracy of our model on the data is:  0.8781333333333333\n",
      "The precision of our model on the data is:  0.8776720683502376\n",
      "The recall of our model on the data is:  0.8768736100900443\n",
      "The f1 score of our model on the data is:  0.8743240991602613\n"
     ]
    }
   ],
   "source": [
    "# One-hotting the dataset for use\n",
    "def createLabel(dataset, metric, percentiles):\n",
    "#     by quintiles\n",
    "#     by manual cutoff\n",
    "    if percentiles == \"thirds\":\n",
    "        dataset.sort_values([metric], ascending=False)\n",
    "        labels = []\n",
    "        for x in range(len(dataset)):\n",
    "            if x < len(dataset) / 3:\n",
    "                labels.append(1)\n",
    "            elif x < len(dataset) / 3 * 2:\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(-1)\n",
    "        dataset[\"Label\"] = labels\n",
    "        #  Need to shuffle because just ranked them by deal count or whatever the metric is...\n",
    "        dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "    else: \n",
    "        print(\"Invalid percentile requested to create labels by \")\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def discretize(vector, range):\n",
    "    newRange = range\n",
    "    vals = [range]\n",
    "    x = True\n",
    "    while(x):\n",
    "        range -= 1\n",
    "        if abs(range) <= newRange:\n",
    "            vals.append(range)\n",
    "        else:\n",
    "            x=False\n",
    "    roundedVals = []\n",
    "    for x in vector:\n",
    "        newVal = int(x)\n",
    "        if abs(newVal) > newRange:\n",
    "            # if greater than the newRange:\n",
    "            if newVal < 0:\n",
    "                newVal = -1*newRange\n",
    "            else:\n",
    "                newVal = 1*newRange\n",
    "        roundedVals.append(newVal)\n",
    "    return roundedVals\n",
    "\n",
    "def assignLabels(employees, metric):\n",
    "    employees_labelled = employees.copy()\n",
    "    employees_labelled = employees.sort_values([metric], ascending=False)\n",
    "    fifth = math.floor(len(employees_labelled) / 5)\n",
    "    num = 2\n",
    "    labels = []\n",
    "    for x in range(5):\n",
    "        for y in range(fifth):\n",
    "            labels.append(num)\n",
    "        num -= 1\n",
    "    employees_labelled[\"Label\"] = labels\n",
    "    employees_labelled = employees_labelled.sample(frac=1).reset_index(drop=True)\n",
    "    return employees_labelled\n",
    "\n",
    "\n",
    "features = [\"Race\", \"Gender\", \"Birth Origin\", \"Criminal Record\",\n",
    "           \"Arrest Record\", \"LinkedIn Score\", \"Responsible Social Media Use\", \n",
    "            \"HireVue Score\", \"Undergraduate Degree\", \"Employee Referral\"]\n",
    "prefixes = [\"race\", \"gender\", \"origin\", \"criminal\", \"arrest\", \"linkedin\", \n",
    "           \"socmedia\", \"hirevue\", \"degree\", \"referral\"]\n",
    "employees_race = employees[\"Race\"]\n",
    "employees_processed = getOnehottedDataset(employees, features, prefixes)\n",
    "employees_processed[\"Race\"] = employees_race\n",
    "employees_processed.columns\n",
    "\n",
    "\n",
    "selectedFeatures = [\n",
    "#     \"Technical Aptitude\", \"Sports\", \"Leadership Capability\"\n",
    "    \"GPA\", \"Education\", \"Educational Prestige\", \"Years of Experience\", \"Soft Skills\",\n",
    "]\n",
    "\n",
    "metric = \"Manager's Assessment Score\"\n",
    "\n",
    "\n",
    "employees_processed = assignLabels(employees_processed, metric)\n",
    "\n",
    "# employees_processed[\"Label\"] = discretize(employees_processed[metric] / 1, 2)\n",
    "print(employees_processed.groupby([\"Label\"]).size())\n",
    "\n",
    "\n",
    "# Currently just a divide by max - normalization scheme...\n",
    "# employees_scaled = transformDatapointsToScale(employees_processed, selectedFeatures)\n",
    "employees_scaled = employees_processed\n",
    "\n",
    "y = employees_scaled[\"Label\"]\n",
    "X = employees_scaled.drop([\"Label\"], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=50)\n",
    "X_train_selectedFeatures = X_train[selectedFeatures].copy()\n",
    "X_test_selectedFeatures = X_test[selectedFeatures].copy()\n",
    "\n",
    "def runLogRegModel(X, y):\n",
    "    oneVsRest = OneVsRestClassifier(LogisticRegression(random_state = 0, max_iter=500))\n",
    "    oneVsRest_fitted = oneVsRest.fit(X, y)\n",
    "    return oneVsRest_fitted\n",
    "\n",
    "model = runLogRegModel(X_train_selectedFeatures, y_train)\n",
    "\n",
    "def getModelStats(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    vals = {}\n",
    "    for x in range(len(y_pred)):\n",
    "        if y_pred[x] not in vals:\n",
    "            vals.update({y_pred[x]: 1})\n",
    "        else: \n",
    "            vals[y_pred[x]] += 1\n",
    "    print(vals)\n",
    "    \n",
    "    \n",
    "    print(\"The accuracy of our model on the data is: \", accuracy_score(y_pred, y))\n",
    "    print(\"The precision of our model on the data is: \", precision_score(y_pred, y, average='macro'))\n",
    "    print(\"The recall of our model on the data is: \", recall_score(y_pred, y, average='macro'))\n",
    "    print(\"The f1 score of our model on the data is: \", f1_score(y_pred, y, average='macro'))\n",
    "    \n",
    "getModelStats(model, X_train_selectedFeatures, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 668, -1: 797, 1: 793, 0: 719, -2: 803}\n",
      "The accuracy of our model on the data is:  0.8579365079365079\n",
      "The precision of our model on the data is:  0.8575495068684829\n",
      "The recall of our model on the data is:  0.8605228192802917\n",
      "The f1 score of our model on the data is:  0.8580094298056336\n"
     ]
    }
   ],
   "source": [
    "# One-hotting the dataset for use\n",
    "features = [\"Race\", \"Gender\", \"Birth Origin\", \"Criminal Record\",\n",
    "           \"Arrest Record\", \"LinkedIn Score\", \"Responsible Social Media Use\", \n",
    "            \"HireVue Score\", \"Undergraduate Degree\", \"Employee Referral\"]\n",
    "prefixes = [\"race\", \"gender\", \"origin\", \"criminal\", \"arrest\", \"linkedin\", \n",
    "           \"socmedia\", \"hirevue\", \"degree\", \"referral\"]\n",
    "employees_race = employees[\"Race\"]\n",
    "employees_processed = getOnehottedDataset(employees, features, prefixes)\n",
    "employees_processed[\"Race\"] = employees_race\n",
    "employees_processed.columns\n",
    "\n",
    "\n",
    "selectedFeatures = [\n",
    "#     \"Technical Aptitude\", \"Sports\", \"Leadership Capability\"\n",
    "    \"GPA\", \"Education\", \"Educational Prestige\", \"Years of Experience\", \"Soft Skills\",\n",
    "]\n",
    "\n",
    "metric = \"Manager's Assessment Score\"\n",
    "\n",
    "employees_processed = assignLabels(employees_processed, metric)\n",
    "employees_scaled = employees_processed\n",
    "\n",
    "y = employees_scaled[\"Label\"]\n",
    "X = employees_scaled.drop([\"Label\"], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=50)\n",
    "\n",
    "X_train_selectedFeatures = X_train[selectedFeatures].copy()\n",
    "X_test_selectedFeatures = X_test[selectedFeatures].copy()\n",
    "\n",
    "\n",
    "def rescaling(X):\n",
    "#     print(X)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X)\n",
    "    data = scaler.transform(X)\n",
    "    return data\n",
    "\n",
    "X_scaled_train = rescaling(X_train_selectedFeatures)\n",
    "# print(X_scaled_train)\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=4, metric=\"minkowski\", p=3)\n",
    "knn_model = neigh.fit(X_scaled_train, y_train)\n",
    "getModelStats(knn_model, X_scaled_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300\n"
     ]
    }
   ],
   "source": [
    "# y = employees[metric]\n",
    "# X = employees.drop([metric], axis=1)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=50)\n",
    "# One-hotting the dataset for use\n",
    "features = [\"Race\", \"Gender\", \"Birth Origin\", \"Criminal Record\",\n",
    "           \"Arrest Record\", \"LinkedIn Score\", \"Responsible Social Media Use\", \n",
    "            \"HireVue Score\", \"Undergraduate Degree\", \"Employee Referral\"]\n",
    "prefixes = [\"race\", \"gender\", \"origin\", \"criminal\", \"arrest\", \"linkedin\", \n",
    "           \"socmedia\", \"hirevue\", \"degree\", \"referral\"]\n",
    "employees_race = employees[\"Race\"]\n",
    "employees_processed = getOnehottedDataset(employees, features, prefixes)\n",
    "employees_processed[\"Race\"] = employees_race\n",
    "employees_processed.columns\n",
    "\n",
    "metric = \"Job Tenure\"\n",
    "\n",
    "\n",
    "# selectedFeatures = [\n",
    "# #                     \"culturalfit_0.0\", \"culturalfit_1.0\", \"culturalfit_2.0\",\n",
    "#                     \"referral_0.0\", \"referral_1.0\",\n",
    "#                     \"hirevue_0.0\", \"hirevue_1.0\", \"hirevue_2.0\",\n",
    "# #                     \"education_0.0\", \"education_1.0\", \"education_2.0\",\n",
    "# #                     \"prestige_0.0\", \"prestige_1.0\", \"prestige_2.0\",\n",
    "#                     \"linkedin_None\", \"linkedin_Ok\", \"linkedin_Very Good\",\n",
    "#                     \"socmedia_Bad\", \"socmedia_Good\", \"criminal_0.0\", \"criminal_1.0\",\n",
    "#                     \"arrest_0.0\", \"arrest_1.0\",\n",
    "#                     \"GPA\", \"Education\", \"Soft Skills\", \"Leadership Capability\", \"Educational Prestige\"\n",
    "#                     ]\n",
    "\n",
    "\n",
    "selectedFeatures = [\n",
    "    \"Military Tenure\", \"Avg Commute Time\", \"Cultural Fit\"\n",
    "]\n",
    "\n",
    "\n",
    "employees_processed = assignLabels(employees_processed, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2 -1  0  1  2]\n",
      "The mean of Military Tenure for employees with -2 is 2.0327192194097012\n",
      "The median of Military Tenure for employees -2 is 2.0087507303433942\n",
      "\n",
      "The mean of Military Tenure for employees with -1 is 2.0270914729212106\n",
      "The median of Military Tenure for employees -1 is 1.9984472324671356\n",
      "\n",
      "The mean of Military Tenure for employees with 0 is 2.0580613502345524\n",
      "The median of Military Tenure for employees 0 is 2.0868398146315377\n",
      "\n",
      "The mean of Military Tenure for employees with 1 is 2.022463938223123\n",
      "The median of Military Tenure for employees 1 is 2.014701234584463\n",
      "\n",
      "The mean of Military Tenure for employees with 2 is 1.9502965105539525\n",
      "The median of Military Tenure for employees 2 is 1.9713203811595867\n",
      "\n",
      "The mean of Avg Commute Time for employees with -2 is 33.21404408351539\n",
      "The median of Avg Commute Time for employees -2 is 30.24591000383782\n",
      "\n",
      "The mean of Avg Commute Time for employees with -1 is 33.051657686912364\n",
      "The median of Avg Commute Time for employees -1 is 28.66533282675496\n",
      "\n",
      "The mean of Avg Commute Time for employees with 0 is 31.71877533075372\n",
      "The median of Avg Commute Time for employees 0 is 29.14797636883429\n",
      "\n",
      "The mean of Avg Commute Time for employees with 1 is 33.16441889635994\n",
      "The median of Avg Commute Time for employees 1 is 30.902486354279787\n",
      "\n",
      "The mean of Avg Commute Time for employees with 2 is 35.24574787150348\n",
      "The median of Avg Commute Time for employees 2 is 33.23701687679014\n",
      "\n",
      "The mean of Cultural Fit for employees with -2 is 0.048163370261576584\n",
      "The median of Cultural Fit for employees -2 is -0.07923967102570817\n",
      "\n",
      "The mean of Cultural Fit for employees with -1 is 0.1152876137169512\n",
      "The median of Cultural Fit for employees -1 is 0.0018628713045057005\n",
      "\n",
      "The mean of Cultural Fit for employees with 0 is 0.014328838691801252\n",
      "The median of Cultural Fit for employees 0 is 0.14926624560081925\n",
      "\n",
      "The mean of Cultural Fit for employees with 1 is -0.07132199350043848\n",
      "The median of Cultural Fit for employees 1 is -0.07984314001724455\n",
      "\n",
      "The mean of Cultural Fit for employees with 2 is -0.1224455801911854\n",
      "The median of Cultural Fit for employees 2 is -0.1750141468335638\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# There needs to be a way to examine the labels e.g. \n",
    "# Is there consistency in valuations among the features for the high performing ppl?\n",
    "\n",
    "def printStats(employees, label, features):\n",
    "    df = employees.copy()\n",
    "    \n",
    "    label_vals = df[label].unique()\n",
    "    label_vals.sort()\n",
    "    print(label_vals)\n",
    "    \n",
    "    for feature in features:\n",
    "        for label_val in label_vals:\n",
    "            selectedFeature = df.loc[(df[label] == label_val)][feature]\n",
    "            print(\"The mean of \" + feature + \" for employees with \" + str(label_val) + \" is\", selectedFeature.mean())\n",
    "            print(\"The median of \" + feature + \" for employees \" + str(label_val) + \" is\", selectedFeature.median())\n",
    "            print(\"\")\n",
    "\n",
    "printStats(employees_processed, \"Label\", [\"Military Tenure\", \"Avg Commute Time\", \"Cultural Fit\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# employees_processed[\"Label\"] = discretize(employees_processed[metric] / 1, 2)\n",
    "print(employees_processed.groupby([\"Label\"]).size())\n",
    "\n",
    "\n",
    "y = employees_processed[\"Label\"]\n",
    "X = employees_processed.drop([\"Label\"], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=50)\n",
    "X_train_selectedFeatures = X_train[selectedFeatures].copy()\n",
    "X_test_selectedFeatures = X_test[selectedFeatures].copy()\n",
    "\n",
    "\n",
    "# Now they get access to a new dataset that has sort of different distributions, they don't know\n",
    "# Task use kNearestNeighbor or LogisticRegression or something else to try and maximize...\n",
    "def rescaling(X):\n",
    "#     print(X)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X)\n",
    "    data = scaler.transform(X)\n",
    "    return data\n",
    "\n",
    "X_scaled_train = rescaling(X_train_selectedFeatures)\n",
    "# print(X_scaled_train)\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=4, metric=\"minkowski\", p=3)\n",
    "knn_model = neigh.fit(X_scaled_train, y_train)\n",
    "\n",
    "\n",
    "getModelStats(knn_model, X_scaled_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
