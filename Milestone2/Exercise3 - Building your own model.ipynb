{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL #\n",
    "import nbimporter\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.linalg import eigh, cholesky\n",
    "from scipy.stats import norm\n",
    "from pylab import plot, show, axis, subplot, xlabel, ylabel, grid\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import accuracys_score, f1_score, recall_score, precision_score\n",
    "# RUN THIS CELL #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL #\n",
    "def getModelStats(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    vals = {}\n",
    "    for x in range(len(y_pred)):\n",
    "        if y_pred[x] not in vals:\n",
    "            vals.update({y_pred[x]: 1})\n",
    "        else: \n",
    "            vals[y_pred[x]] += 1\n",
    "    print(vals)\n",
    "    print(\"The accuracy of our model on the data is: \", accuracy_score(y_pred, y))\n",
    "    print(\"The precision of our model on the data is: \", precision_score(y_pred, y, average='macro'))\n",
    "    print(\"The recall of our model on the data is: \", recall_score(y_pred, y, average='macro'))\n",
    "    print(\"The f1 score of our model on the data is: \", f1_score(y_pred, y, average='macro'))\n",
    "\n",
    "            \n",
    "def classificationSelection(candidates, labels, acceptValue):\n",
    "    df = candidates.copy()\n",
    "    df[\"Labels\"] = labels\n",
    "    candidatesSelected = df[df[\"Labels\"].isin([acceptValue])]\n",
    "    return candidatesSelected\n",
    "\n",
    "def getOnehottedDataset(dataset, features, prefixes):\n",
    "# race, sex, sports, birth origin, education, educational prestige, criminal record, arrest record,\n",
    "    onehotted_data = dataset.copy()\n",
    "    onehotted_data = pd.get_dummies(onehotted_data, columns=features, prefix=prefixes)\n",
    "    return onehotted_data\n",
    "\n",
    "\n",
    "def graphSelectionRates(selected, candidates, protectedClass):\n",
    "    selected_candidates = selected.copy()\n",
    "    candidates_all = candidates.copy()\n",
    "    raceIndxs = {\"Caucasian\": 0, \"African-American\": 1, \"Asian\": 2, \"Hispanic\": 3, \"Other\": 4 }\n",
    "    sexIndxs = {\"Male\":0, \"Female\":1}\n",
    "    \n",
    "    if protectedClass == \"race\":\n",
    "        features = [col for col in selected_candidates if col.startswith(\"race_\")]\n",
    "        race_selected = selected_candidates[features].idxmax(axis=1).str.replace('race_', '')\n",
    "        race_all = candidates_all[features].idxmax(axis=1).str.replace('race_', '')\n",
    "        \n",
    "        candidates_all[\"Race\"] = race_all\n",
    "        selected_candidates[\"Race\"] = race_selected\n",
    "\n",
    "        numCandidates = candidates_all[\"Race\"].value_counts()\n",
    "        numQualified = selected_candidates[\"Race\"].value_counts()\n",
    "\n",
    "        selectionRate1 = numQualified[\"Caucasian\"] / numCandidates[\"Caucasian\"]\n",
    "        selectionRate2 = numQualified[\"Asian\"] / numCandidates[\"Asian\"]\n",
    "        selectionRate3 = numQualified[\"African-American\"] / numCandidates[\"African-American\"]\n",
    "        selectionRate4 = numQualified[\"Hispanic\"] / numCandidates[\"Hispanic\"]\n",
    "        \n",
    "        print(\"The selection rate for \" + \"Caucasian\" + \"s: \",selectionRate1)\n",
    "        print(\"The selection rate for \" + \"Asian\" + \"s: \", selectionRate2)\n",
    "        print(\"The selection rate for \" + \"African-American\" + \"s: \",selectionRate3)\n",
    "        print(\"The selection rate for \" + \"Hispanic\" + \"s: \",selectionRate4)\n",
    "        \n",
    "        y_pos = np.arange(4)\n",
    "        performance = [selectionRate1, selectionRate2, selectionRate3, selectionRate4]\n",
    "        plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "        plt.xticks(y_pos, (\"Caucasian\", \"Asian\", \"African-American\", \"Hispanic\"))\n",
    "        plt.ylabel('Selection Rate')\n",
    "        plt.title('Selection Rate Comparisons by Race')\n",
    "        plt.show()\n",
    "    elif protectedClass == \"gender\":\n",
    "        features = [col for col in selected_candidates if col.startswith(\"gender_\")]\n",
    "        gender_selected = selected_candidates[features].idxmax(axis=1).str.replace('gender_', '')\n",
    "        gender_all = candidates_all[features].idxmax(axis=1).str.replace('gender_', '')\n",
    "\n",
    "        candidates_all[\"Gender\"] = gender_all\n",
    "        selected_candidates[\"Gender\"] = gender_selected\n",
    "        \n",
    "        numCandidates = candidates_all[\"Gender\"].value_counts()\n",
    "        numQualified = selected_candidates[\"Gender\"].value_counts()\n",
    "        \n",
    "        print(numCandidates)\n",
    "        print(numQualified) \n",
    "        \n",
    "        maleSelectionRate = numQualified[\"male\"] / numCandidates[\"male\"]\n",
    "        femaleSelectionRate = numQualified[\"female\"] / numCandidates[\"female\"]\n",
    "        print(\"The selection rate for \" + \"Male\" + \"s: \", maleSelectionRate)\n",
    "        print(\"The selection rate for \" + \"Female\" + \"s: \", femaleSelectionRate)\n",
    "        y_pos = np.arange(2)\n",
    "        performance = [maleSelectionRate, femaleSelectionRate]\n",
    "        plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "        plt.xticks(y_pos, (\"Male\", \"Female\"))\n",
    "        plt.ylabel('Selection Rate')\n",
    "        plt.title('Selection Rate Comparisons by Sex')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Try another protected type - gender or race\")\n",
    "        \n",
    "\n",
    "# Takes the dataset and returns all members in the dataset whose protectedClass is of the value\n",
    "# For example, if protectedClass=race and value=\"African-American\", returns all African-Americans in the dataset.\n",
    "def selectPersonsInClass(data, protectedClass, value):\n",
    "    df = data.loc[(data[protectedClass] == value)]\n",
    "    print(\"Num of rows of ppl who are %s:\"% (value ,), len(df))\n",
    "    return df\n",
    "# RUN THIS CELL #    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL #  \n",
    "# Loading the dataset\n",
    "employees = pd.read_csv(\"../Employees_M2/employees_milestone2.csv\")\n",
    "candidates = pd.read_csv(\"../Candidates_M2/candidates_milestone2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 49 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Names                       10000 non-null  object \n",
      " 1   Age                         10000 non-null  float64\n",
      " 2   Zip                         10000 non-null  int64  \n",
      " 3   Education                   10000 non-null  int64  \n",
      " 4   GPA                         10000 non-null  float64\n",
      " 5   Educational Prestige        10000 non-null  float64\n",
      " 6   Years of Experience         10000 non-null  float64\n",
      " 7   Soft Skills                 10000 non-null  float64\n",
      " 8   Manager's Assessment Score  10000 non-null  float64\n",
      " 9   Military Tenure             10000 non-null  float64\n",
      " 10  Avg Commute Time            10000 non-null  float64\n",
      " 11  Job Tenure                  10000 non-null  float64\n",
      " 12  Cultural Fit                10000 non-null  float64\n",
      " 13  Leadership Capability       10000 non-null  float64\n",
      " 14  HireVue Score               10000 non-null  float64\n",
      " 15  Technical Aptitude          10000 non-null  float64\n",
      " 16  Avg Deals Closed            10000 non-null  float64\n",
      " 17  race_African-American       10000 non-null  uint8  \n",
      " 18  race_Asian                  10000 non-null  uint8  \n",
      " 19  race_Caucasian              10000 non-null  uint8  \n",
      " 20  race_Hispanic               10000 non-null  uint8  \n",
      " 21  race_Other                  10000 non-null  uint8  \n",
      " 22  gender_female               10000 non-null  uint8  \n",
      " 23  gender_male                 10000 non-null  uint8  \n",
      " 24  origin_Australia            10000 non-null  uint8  \n",
      " 25  origin_Canada               10000 non-null  uint8  \n",
      " 26  origin_China                10000 non-null  uint8  \n",
      " 27  origin_Mexico               10000 non-null  uint8  \n",
      " 28  origin_USA                  10000 non-null  uint8  \n",
      " 29  criminal_0.0                10000 non-null  uint8  \n",
      " 30  criminal_1.0                10000 non-null  uint8  \n",
      " 31  arrest_0.0                  10000 non-null  uint8  \n",
      " 32  arrest_1.0                  10000 non-null  uint8  \n",
      " 33  arrest_2.0                  10000 non-null  uint8  \n",
      " 34  sports_0.0                  10000 non-null  uint8  \n",
      " 35  sports_1.0                  10000 non-null  uint8  \n",
      " 36  linkedin_None               10000 non-null  uint8  \n",
      " 37  linkedin_Ok                 10000 non-null  uint8  \n",
      " 38  linkedin_Very Good          10000 non-null  uint8  \n",
      " 39  socmedia_Bad                10000 non-null  uint8  \n",
      " 40  socmedia_Good               10000 non-null  uint8  \n",
      " 41  degree_Engineering          10000 non-null  uint8  \n",
      " 42  degree_Humanities           10000 non-null  uint8  \n",
      " 43  degree_None                 10000 non-null  uint8  \n",
      " 44  degree_Quantitative         10000 non-null  uint8  \n",
      " 45  degree_Sciences             10000 non-null  uint8  \n",
      " 46  referral_0.0                10000 non-null  uint8  \n",
      " 47  referral_1.0                10000 non-null  uint8  \n",
      " 48  Race                        10000 non-null  object \n",
      "dtypes: float64(14), int64(2), object(2), uint8(31)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# RUN THIS CELL (0 Lines) #\n",
    "# One-hotting the dataset for use #\n",
    "features = [\"Race\", \"Gender\", \"Birth Origin\", \"Criminal Record\", \"Sports\",\n",
    "           \"Arrest Record\", \"LinkedIn Score\", \"Responsible Social Media Use\", \"Undergraduate Degree\", \"Employee Referral\"]\n",
    "prefixes = [\"race\", \"gender\", \"origin\", \"criminal\", \"arrest\", \"sports\", \"linkedin\", \n",
    "           \"socmedia\", \"degree\", \"referral\"]\n",
    "employees_race = employees[\"Race\"]\n",
    "candidates_race = candidates[\"Race\"]\n",
    "employees_processed = getOnehottedDataset(employees, features, prefixes)\n",
    "employees_processed[\"Race\"] = employees_race\n",
    "candidates_processed = getOnehottedDataset(candidates, features, prefixes)\n",
    "candidates_processed[\"Race\"] = candidates_race\n",
    "employees_processed.info()\n",
    "# RUN THIS CELL #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 2\n",
    "## Exercise 3: Deploying a Model. \n",
    "\n",
    "Ok in this final exercise your team will be tasked with choosing, tweaking, and/or building a model to deploy on our prospective job candidates! You're then going to be asked to settle on your approach and discuss your process and addressal of challenges in a memo. Exciting & precarious stuff!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Data Engineering\n",
    "\n",
    "In this section you'll decide on which features to include, segments of data to include/exclude, a performance metric, and method of label generation for your employees. It's not necessary to think of these needing to be done in a particular order.\n",
    "\n",
    "- Choose features.\n",
    "- Include/Exclude Data - Change the distribution of the dataset for different training results.\n",
    "- Formulating a performance metric.\n",
    "- Formulate a label generation method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting Features: Ok, you're going to want to select some features based on what's available to you now that we've one-hotted the dataset. Some key considerations...\n",
    "- What features are the most predictive of performance\n",
    "- What features may be useful for some subgroups but not others. \n",
    "- What features may have unequal distributions between different group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose features and metric to use for your model (1 Line)\n",
    "selectedFeatures = [\n",
    "    \"GPA\", \"Educational Prestige\", \"Technical Aptitude\", \"hirevue_2.0\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a Metric:  Some key considerations...\n",
    "- Is the metric's value distribution equal among the different groups? \n",
    "- Could some \"linear combination\" of the metrics be more predictive or meaningful to you?\n",
    "- Should your metric include non-performance related features like GPA, or cultural fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pre-existing or make your own metric! (1 Line)\n",
    "metric = \"Avg Deals Closed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick a Label Generation Method: Here we've chosen a metric to use as part of our model training. If you're planning on using a regression technique then you can skip this method as you'll be directly training to predict the metric score. However if you're using a classification algorithm then you need to bucket the employees in some way. \n",
    "\n",
    "Some considerations...\n",
    "- Does my label generation method make me vulnerable to false positives? false negatives?\n",
    "- How will my resulting labels be used to make the actual decision when it comes to candidates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Label Generation Method (3-5 Lines) #\n",
    "def assignLabelsByPercentile(employees, metric, percentile):\n",
    "    employees_labelled = employees.copy()\n",
    "    employees_labelled = employees_labelled.sort_values([metric], ascending=False)\n",
    "    nths = math.floor(len(employees_labelled) / percentile)\n",
    "    num = percentile - 1\n",
    "    labels = []\n",
    "    for x in range(percentile):\n",
    "        for y in range(nths):\n",
    "            labels.append(num)\n",
    "        num -= 1\n",
    "    while (len(labels) != len(employees)):\n",
    "        labels.append(np.random.choice(percentile))\n",
    "    employees_labelled[\"Label\"] = labels\n",
    "    \n",
    "    employees_labelled = employees_labelled.sample(frac=1).reset_index(drop=True)\n",
    "    return employees_labelled \n",
    "\n",
    "employees_labelled = assignLabelsByPercentile(employees_processed, metric, 7)\n",
    "# Insert Label Generation Method (3-5 Lines) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulating your Dataset: Due to bias, or the relative importance of some features you saw in the last exercises, your team may want to meaningfully manipulate features in the dataset some way.  \n",
    "\n",
    "#### If you're using k Nearest Neighbors you may just want to normalize certain features so that one or two of them don't drive the entirety of the distance sum. You may also want to remove a subset of the data because it is somehow causing poorer performance due to its outlying nature or you want to rectify some imbalance in the data.\n",
    "\n",
    "Some key considerations - \n",
    "- Will my manipulations applied mitigate or accentuate existing biases in the data?\n",
    "- How will my adjustments affect not just the bias but the actual model's performance?\n",
    "- Do I risk overfitting the model by the way I'm thinking about certain candidates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove/alter certain data features # (0-5 Lines)\n",
    "\n",
    "# Remove/alter certain data features #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform, scale, & adjust the data (0-10 Lines)\n",
    "def transformDatapointsToScale(dataset, selectedFeatures):\n",
    "    df = dataset.copy()\n",
    "    for feature in selectedFeatures:\n",
    "        maximum = df[feature].max()\n",
    "        df[feature] = df[feature].apply(lambda x: x / maximum)\n",
    "    return df\n",
    "\n",
    "X = transformDatapointsToScale(employees_labelled[selectedFeatures].copy(), selectedFeatures)\n",
    "y = employees_labelled[\"Label\"] \n",
    "# Transform, scale, & adjust the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell #\n",
    "# Split into train, test ... #\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=50)\n",
    "# Run this cell #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Picking a model to deploy\n",
    "\n",
    "Ok now that you've been able to experiment with a model, and gained understanding of its architecture, its performance, its advantages and disadvantages. You and your team are now going to settle on a particular model to elect candidates for the next round of hires!\n",
    "\n",
    "You are free to choose any of the architectures including the naive ranking and nearest neighbor models from Milestone 1 as your model as well as any of the ones we have covered here. If your team is already comfortable with the models covered, you are freee to use another model architecture that you're team wants to test.  \n",
    "\n",
    "Just know that you will have to answer a number of questions about its use and performance in the following sections.\n",
    "\n",
    "Some key considerations ...\n",
    "- How will my model interact with the decisions I've made about features. \n",
    "- Can our team explain why the model is coming to the predictions it is coming to?\n",
    "- What's the performance? (Task 3)\n",
    "- Are there any hyperparameters that you can test different values with for this model? If so, what are they and how might they affect your score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT MODEL ARCHITECTURE # (1 Line)\n",
    "# model = OneVsRestClassifier(LogisticRegression(random_state = 0, max_iter=500))\n",
    "# INSERT MODEL ARCHITECTURE #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Running & Analyzing Initial Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 1075, 3: 1326, 0: 1444, 5: 930, 4: 723, 2: 599, 6: 1403}\n",
      "The accuracy of our model on the data is:  0.6952\n",
      "The precision of our model on the data is:  0.6939512298701812\n",
      "The recall of our model on the data is:  0.6962357292760232\n",
      "The f1 score of our model on the data is:  0.679564208651862\n"
     ]
    }
   ],
   "source": [
    "# RUN THIS CELL (0 Lines) #\n",
    "logreg_model = model.fit(X_train, y_train)\n",
    "getModelStats(logreg_model, X_train, y_train)\n",
    "# RUN THIS CELL #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Analyzing Fairness of the Model\n",
    "Here we'd like you to apply some of the concepts and fairness notions we gave to you in the last exercise to make a determination of the model's equity in its predictions. No rigorous examination is required but you should try to calculate some of the metrics introduced among the different subgroups for your model...\n",
    "\n",
    "- We've given an example of what one simple approach might be below - examining the accuracy of the model on different subgroups.\n",
    "\n",
    "Key Considerations ...\n",
    "- Is there a potential differential validity problem present? (Hint: Check weights if utilizing regressions)\n",
    "- Is my model more susceptible to false positives or false negatives - how can I illustrate that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats are for following class:  African-American\n",
      "{6: 1890, 1: 1430, 4: 951, 3: 1743, 0: 1908, 2: 811, 5: 1267}\n",
      "The accuracy of our model on the data is:  0.6936\n",
      "The precision of our model on the data is:  0.6936130804996617\n",
      "The recall of our model on the data is:  0.6951058591540547\n",
      "The f1 score of our model on the data is:  0.6784237884648591\n",
      "\n",
      "Stats are for following class:  Caucasian\n",
      "{6: 1890, 1: 1430, 4: 951, 3: 1743, 0: 1908, 2: 811, 5: 1267}\n",
      "The accuracy of our model on the data is:  0.6936\n",
      "The precision of our model on the data is:  0.6936130804996617\n",
      "The recall of our model on the data is:  0.6951058591540547\n",
      "The f1 score of our model on the data is:  0.6784237884648591\n",
      "\n",
      "Stats are for following class:  Hispanic\n",
      "{6: 1890, 1: 1430, 4: 951, 3: 1743, 0: 1908, 2: 811, 5: 1267}\n",
      "The accuracy of our model on the data is:  0.6936\n",
      "The precision of our model on the data is:  0.6936130804996617\n",
      "The recall of our model on the data is:  0.6951058591540547\n",
      "The f1 score of our model on the data is:  0.6784237884648591\n",
      "\n",
      "Stats are for following class:  Other\n",
      "{6: 1890, 1: 1430, 4: 951, 3: 1743, 0: 1908, 2: 811, 5: 1267}\n",
      "The accuracy of our model on the data is:  0.6936\n",
      "The precision of our model on the data is:  0.6936130804996617\n",
      "The recall of our model on the data is:  0.6951058591540547\n",
      "The f1 score of our model on the data is:  0.6784237884648591\n",
      "\n",
      "Stats are for following class:  Asian\n",
      "{6: 1890, 1: 1430, 4: 951, 3: 1743, 0: 1908, 2: 811, 5: 1267}\n",
      "The accuracy of our model on the data is:  0.6936\n",
      "The precision of our model on the data is:  0.6936130804996617\n",
      "The recall of our model on the data is:  0.6951058591540547\n",
      "The f1 score of our model on the data is:  0.6784237884648591\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# INSERT Fairness Metrics # (3-10 Lines)\n",
    "\n",
    "# Checking the accuracy amongst distinct groups\n",
    "races = [\"African-American\", \"Caucasian\", \"Hispanic\", \"Other\", \"Asian\"]\n",
    "for race in races:\n",
    "    print(\"Stats are for following class: \", race)\n",
    "    x_class = transformDatapointsToScale(employees_labelled, selectedFeatures)\n",
    "    y_class = x_class[\"Label\"]\n",
    "    x_class = x_class[selectedFeatures].copy()\n",
    "    getModelStats(logreg_model, x_class, y_class)\n",
    "    print(\"\")\n",
    "    \n",
    "    \n",
    "# Examining the model weights in the model per class....\n",
    "coeff_values = list(logreg_model.coef_)\n",
    "features = list(logreg_model.classes_)\n",
    "assert(len(coeff_values) == len(features))\n",
    "featureToValues = {features[x] : coeff_values[x] for x in range(len(features))}\n",
    "print(featureToValues)\n",
    "    \n",
    "# INSERT # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Deploying on Candidates!\n",
    "- Alright we've finally gotten to where your team can use the model you've built on the candidate dataset and see the results. Before we run it though, recall there's one last major step. Choosing a selection method. If you decided on a classification algorithm you may have decided that candidates assigned the best label are those selected for the next round. But that's not the only way to do things. Be as creative as you'd like to be!\n",
    "\n",
    "Key Considerations ...\n",
    "- What was the label generation method you chose, what labels are therefore most predictive of performance. \n",
    "- Is the selection method to narrow? to general?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL (1-3 Lines) #\n",
    "X_candidates = transformDatapointsToScale(candidates_processed[selectedFeatures].copy(), selectedFeatures)\n",
    "candidate_labels = logreg_model.predict(X_candidates)\n",
    "# RUN THIS CELL #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT Selection Method # (3-10 Lines)\n",
    "def classificationSelection(candidates, labels, acceptValue):\n",
    "    df = candidates.copy()\n",
    "    df[\"Labels\"] = labels\n",
    "    candidatesSelected = df[df[\"Labels\"].isin([acceptValue])]\n",
    "    return candidatesSelected\n",
    "\n",
    "candidatesSelected = classificationSelection(candidates_processed, candidate_labels, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally! Time to give it a shot on the dataset and we'll see how we do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selection rate for Caucasians:  0.09818181818181818\n",
      "The selection rate for Asians:  0.09333333333333334\n",
      "The selection rate for African-Americans:  0.08571428571428572\n",
      "The selection rate for Hispanics:  0.06\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run This Cell (1-3 Lines) #\n",
    "graphSelectionRates(candidatesSelected, candidates_processed, \"race\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Iterate!\n",
    "\n",
    "So, you may be ecstatic or baffled with your results. Either way, the point now is to try and iteratively improve your approach so that your team is satisfied with the model's performance or thinks they can justify their decisions and the model's behavior. Now that you made your first way through, take the time to think about changing your data engineering process, model architecture, selection methods, etc. to try and improve results. Recall that \"improving\" can mean different things for different folks based on your priorities. For some that will mean enhancing the accuracy of the model on the employees. For others it will be rectifying the disparate outcomes on the candidate dataset. Some will need to narrow their selection rate overall, ohers will need to widen it. \n",
    "\n",
    "Your team may not arrive at an approach you are wholly satisfied with - that's totally alright! Sometimes these problems can seem or even be intractable. Nonetheless, along each of these tasks (1-5), unless you're perfectly happy with the results, you should try at least one to two changes per stage and see what effect it has. You'll need to discuss that experimentation in this final task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Task: Memo Write-up\n",
    "\n",
    "Alright time to finally put your writing cap back on.  Now that you've come to an approach you're satisfied with (or settled on), the GC\"s office wants a ~2 page write-up of your approach, its advantages, disadvantages, threats of statutory liability, and defenses you should lay out the memo in the following manner.\n",
    "\n",
    "Memo Outline & Additional Questions...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
