{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RUN THIS CELL (0 Lines) ###\n",
    "# Load software packages #\n",
    "import nbimporter\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.linalg import eigh, cholesky\n",
    "from scipy.stats import norm\n",
    "from pylab import plot, show, axis, subplot, xlabel, ylabel, grid\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "### RUN THIS CELL ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL (0 Lines) #\n",
    "# getModelStats - takes a model and has it predict on X. Then accuracy, precision, and recall on X is printed.\n",
    "# @params \n",
    "#. model - fitted model \n",
    "#  X - df of individuals with selectedFeatures, \n",
    "#  y - labels of X individuals.\n",
    "def getModelStats(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    vals = {}\n",
    "    for x in range(len(y_pred)):\n",
    "        if y_pred[x] not in vals:\n",
    "            vals.update({y_pred[x]: 1})\n",
    "        else: \n",
    "            vals[y_pred[x]] += 1\n",
    "    print(vals)\n",
    "    print(\"The accuracy of our model on the data is: \", accuracy_score(y_pred, y))\n",
    "    print(\"The precision of our model on the data is: \", precision_score(y_pred, y, average='macro'))\n",
    "    print(\"The recall of our model on the data is: \", recall_score(y_pred, y, average='macro'))\n",
    "\n",
    "# classificationSelection - selects candidates w. \"Labels\" field value of acceptValue\n",
    "# @param\n",
    "#.   - candidates is a dataframe of candidates\n",
    "#.   - labels is an array of the predictions for the candidates\n",
    "#.   - acceptValue is the label value we are seeking for candidates to be selected\n",
    "# @return\n",
    "#.   - candidatesSelected is a dataframe of selected candidates.\n",
    "def classificationSelection(candidates, labels, acceptValue):\n",
    "    df = candidates.copy()\n",
    "    df[\"Labels\"] = labels\n",
    "    candidatesSelected = df[df[\"Labels\"].isin([acceptValue])]\n",
    "    return candidatesSelected\n",
    "\n",
    "# getOnehottedDataset - takes a dataframe, a set of features, and prefix names for those features, and one-hots those features.\n",
    "# Note: ENSURE that the features passed in are discrete/not continuous. \n",
    "# @params: \n",
    "#    - dataset is a dataframe of individuals you seek to onehot the features of\n",
    "#    - features is an array of features in the dataset you wish to one-hot\n",
    "#    - prefixes is an array of names that will be the prefixes of the new columns produced via the one-hot function\n",
    "# @return: \n",
    "#    - returns the dataset with the features, one-hotted.        \n",
    "def getOnehottedDataset(dataset, features, prefixes):\n",
    "    onehotted_data = dataset.copy()\n",
    "    onehotted_data = pd.get_dummies(onehotted_data, columns=features, prefix=prefixes)\n",
    "    return onehotted_data\n",
    "\n",
    "# graphSelectionRates - outputs a bar graph of the selection rates for each protectedClass, depending on the protected\n",
    "# class you pass in (race or gender). \n",
    "# @params: \n",
    "#    - selected is a dataframe of all of the candidates that were chosen by the algorithm\n",
    "#    - candidates is a dataframe containing all candidates\n",
    "#    - protectedClass is a flag passed in as either \"race\" or \"gender\" depending on what the selection rates you'd like\n",
    "# @return: \n",
    "#    - prints selection rates and a bar graph.\n",
    "def graphSelectionRates(selected, candidates, protectedClass):\n",
    "    selected_candidates = selected.copy()\n",
    "    candidates_all = candidates.copy()\n",
    "    raceIndxs = {\"Caucasian\": 0, \"African-American\": 1, \"Asian\": 2, \"Hispanic\": 3, \"Other\": 4 }\n",
    "    sexIndxs = {\"Male\":0, \"Female\":1}\n",
    "    \n",
    "    if protectedClass == \"race\":\n",
    "        features = [col for col in selected_candidates if col.startswith(\"race_\")]\n",
    "        race_selected = selected_candidates[features].idxmax(axis=1).str.replace('race_', '')\n",
    "        race_all = candidates_all[features].idxmax(axis=1).str.replace('race_', '')\n",
    "        \n",
    "        candidates_all[\"Race\"] = race_all\n",
    "        selected_candidates[\"Race\"] = race_selected\n",
    "\n",
    "        numCandidates = candidates_all[\"Race\"].value_counts()\n",
    "        numQualified = selected_candidates[\"Race\"].value_counts()\n",
    "\n",
    "        selectionRate1 = numQualified[\"Caucasian\"] / numCandidates[\"Caucasian\"]\n",
    "        selectionRate2 = numQualified[\"Asian\"] / numCandidates[\"Asian\"]\n",
    "        selectionRate3 = numQualified[\"African-American\"] / numCandidates[\"African-American\"]\n",
    "        selectionRate4 = numQualified[\"Hispanic\"] / numCandidates[\"Hispanic\"]\n",
    "        selectionRate5 = numQualified[\"Other\"] / numCandidates[\"Other\"]\n",
    "        \n",
    "        print(\"The selection rate for \" + \"Caucasian\" + \"s: \",selectionRate1)\n",
    "        print(\"The selection rate for \" + \"Asian\" + \"s: \", selectionRate2)\n",
    "        print(\"The selection rate for \" + \"African-American\" + \"s: \",selectionRate3)\n",
    "        print(\"The selection rate for \" + \"Hispanic\" + \"s: \",selectionRate4)\n",
    "        print(\"The selection rate for \" + \"Other Race\" + \"s: \", selectionRate5)\n",
    "        \n",
    "        y_pos = np.arange(5)\n",
    "        performance = [selectionRate1, selectionRate2, selectionRate3, selectionRate4, selectionRate5]\n",
    "        plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "        plt.xticks(y_pos, (\"Caucasian\", \"Asian\", \"African-American\", \"Hispanic\", \"Other\"))\n",
    "        plt.ylabel('Selection Rate')\n",
    "        plt.title('Selection Rate Comparisons by Race')\n",
    "        plt.show()\n",
    "    elif protectedClass == \"gender\":\n",
    "        \n",
    "        features = [col for col in selected_candidates if col.startswith(\"gender_\")]\n",
    "        gender_selected = selected_candidates[features].idxmax(axis=1).str.replace('gender_', '')\n",
    "        gender_all = candidates_all[features].idxmax(axis=1).str.replace('gender_', '')\n",
    "\n",
    "        candidates_all[\"Gender\"] = gender_all\n",
    "        selected_candidates[\"Gender\"] = gender_selected\n",
    "        \n",
    "        numCandidates = candidates_all[\"Gender\"].value_counts()\n",
    "        numQualified = selected_candidates[\"Gender\"].value_counts()\n",
    "        \n",
    "        print(numCandidates)\n",
    "        print(numQualified) \n",
    "        \n",
    "        maleSelectionRate = numQualified[\"male\"] / numCandidates[\"male\"]\n",
    "        femaleSelectionRate = numQualified[\"female\"] / numCandidates[\"female\"]\n",
    "        print(\"The selection rate for \" + \"Male\" + \"s: \", maleSelectionRate)\n",
    "        print(\"The selection rate for \" + \"Female\" + \"s: \", femaleSelectionRate)\n",
    "        y_pos = np.arange(2)\n",
    "        performance = [maleSelectionRate, femaleSelectionRate]\n",
    "        plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "        plt.xticks(y_pos, (\"Male\", \"Female\"))\n",
    "        plt.ylabel('Selection Rate')\n",
    "        plt.title('Selection Rate Comparisons by Sex')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Try another protected type - gender or race\")\n",
    "\n",
    "# selectPersonsInClass - Takes the dataset and returns all members in the dataset whose protectedClass is of the value\n",
    "# For example, if protectedClass=race and value=\"African-American\", returns all African-Americans in the dataset.\n",
    "# @params\n",
    "#.  - data - is the df of individuals we want to select individuals from\n",
    "#.  - protectedClass - is the protected class, race, gender, etc. we want to select from\n",
    "#.  - value - value is the group within that protected Class we want to select out (e.g female, or hispanic)\n",
    "#. @returns\n",
    "#.  - df the individuals in the selected group in the protected class of the data.\n",
    "def selectPersonsInClass(data, protectedClass, value):\n",
    "    df = data.loc[(data[protectedClass] == value)]\n",
    "    print(\"Num of rows of ppl who are %s:\"% (value ,), len(df))\n",
    "    return df\n",
    "\n",
    "# RUN THIS CELL #    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 2\n",
    "## Exercise 3: Deploying a Model. \n",
    "\n",
    "After working will small and large datasets, testing various algorithmic models from a naive ranking system to kNN, and carefully analyzng tough aspects of algorithmic fairness in these models and where they fail, its time for your crew of legal engineers to try to develop and deploy your own model!\n",
    "\n",
    "You have been tasked with choosing, tweaking, and/or building a model to deploy on our prospective Sprawlmart sales associate job candidates! You're then going to be asked to settle on your approach and discuss your process and addressal of challenges in a memo. Exciting & precarious stuff!\n",
    "\n",
    "We've gone and implemented a barebones multi-class Logistic Regression Model. If that sounds scary don't worry, its really not too complicated and its sipmly meant to be a placeholder as your team walks through the exercise and decides on your own approach so you know what parts of code should go where!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL (0 Lines) #  \n",
    "# Loading the dataset\n",
    "employees = pd.read_csv(\"../Employees_M2/employees_milestone2.csv\")\n",
    "candidates = pd.read_csv(\"../Candidates_M2/candidates_milestone2.csv\")\n",
    "# RUN THIS CELL #  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 49 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Names                       10000 non-null  object \n",
      " 1   Age                         10000 non-null  float64\n",
      " 2   Zip                         10000 non-null  int64  \n",
      " 3   Education                   10000 non-null  int64  \n",
      " 4   GPA                         10000 non-null  float64\n",
      " 5   Educational Prestige        10000 non-null  float64\n",
      " 6   Years of Experience         10000 non-null  float64\n",
      " 7   Soft Skills                 10000 non-null  float64\n",
      " 8   Manager's Assessment Score  10000 non-null  float64\n",
      " 9   Military Tenure             10000 non-null  float64\n",
      " 10  Avg Commute Time            10000 non-null  float64\n",
      " 11  Job Tenure                  10000 non-null  float64\n",
      " 12  Cultural Fit                10000 non-null  float64\n",
      " 13  Leadership Capability       10000 non-null  float64\n",
      " 14  HireVue Score               10000 non-null  float64\n",
      " 15  Technical Aptitude          10000 non-null  float64\n",
      " 16  Avg Deals Closed            10000 non-null  float64\n",
      " 17  race_African-American       10000 non-null  uint8  \n",
      " 18  race_Asian                  10000 non-null  uint8  \n",
      " 19  race_Caucasian              10000 non-null  uint8  \n",
      " 20  race_Hispanic               10000 non-null  uint8  \n",
      " 21  race_Other                  10000 non-null  uint8  \n",
      " 22  gender_female               10000 non-null  uint8  \n",
      " 23  gender_male                 10000 non-null  uint8  \n",
      " 24  origin_Australia            10000 non-null  uint8  \n",
      " 25  origin_Canada               10000 non-null  uint8  \n",
      " 26  origin_China                10000 non-null  uint8  \n",
      " 27  origin_Mexico               10000 non-null  uint8  \n",
      " 28  origin_USA                  10000 non-null  uint8  \n",
      " 29  criminal_0.0                10000 non-null  uint8  \n",
      " 30  criminal_1.0                10000 non-null  uint8  \n",
      " 31  arrest_0.0                  10000 non-null  uint8  \n",
      " 32  arrest_1.0                  10000 non-null  uint8  \n",
      " 33  arrest_2.0                  10000 non-null  uint8  \n",
      " 34  sports_0.0                  10000 non-null  uint8  \n",
      " 35  sports_1.0                  10000 non-null  uint8  \n",
      " 36  linkedin_None               10000 non-null  uint8  \n",
      " 37  linkedin_Ok                 10000 non-null  uint8  \n",
      " 38  linkedin_Very Good          10000 non-null  uint8  \n",
      " 39  socmedia_Bad                10000 non-null  uint8  \n",
      " 40  socmedia_Good               10000 non-null  uint8  \n",
      " 41  degree_Engineering          10000 non-null  uint8  \n",
      " 42  degree_Humanities           10000 non-null  uint8  \n",
      " 43  degree_None                 10000 non-null  uint8  \n",
      " 44  degree_Quantitative         10000 non-null  uint8  \n",
      " 45  degree_Sciences             10000 non-null  uint8  \n",
      " 46  referral_0.0                10000 non-null  uint8  \n",
      " 47  referral_1.0                10000 non-null  uint8  \n",
      " 48  Race                        10000 non-null  object \n",
      "dtypes: float64(14), int64(2), object(2), uint8(31)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# RUN THIS CELL (0 Lines) #\n",
    "# One-hotting the dataset for use #\n",
    "features = [\"Race\", \"Gender\", \"Birth Origin\", \"Criminal Record\", \"Sports\",\n",
    "           \"Arrest Record\", \"LinkedIn Score\", \"Responsible Social Media Use\", \"Undergraduate Degree\", \"Employee Referral\"]\n",
    "prefixes = [\"race\", \"gender\", \"origin\", \"criminal\", \"arrest\", \"sports\", \"linkedin\", \n",
    "           \"socmedia\", \"degree\", \"referral\"]\n",
    "employees_race = employees[\"Race\"]\n",
    "candidates_race = candidates[\"Race\"]\n",
    "employees_processed = getOnehottedDataset(employees, features, prefixes)\n",
    "employees_processed[\"Race\"] = employees_race\n",
    "candidates_processed = getOnehottedDataset(candidates, features, prefixes)\n",
    "candidates_processed[\"Race\"] = candidates_race\n",
    "employees_processed.info()\n",
    "# RUN THIS CELL #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Data Engineering\n",
    "\n",
    "In this section you'll decide on which features to include, segments of data to include/exclude, a performance metric, and method of label generation for your employees. It's not necessary to think of these as needing to be done in a particular order.\n",
    "\n",
    "- Choose features.\n",
    "- Include/Exclude Data - Change the distribution of the dataset for different training results.\n",
    "- Formulating a performance metric.\n",
    "- Formulate a label generation method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting Features: Ok, you're going to want to select some features based on what's available to you now that we've one-hotted the dataset. Some key considerations...\n",
    "- What features are the most predictive of performance\n",
    "- What features may be useful for some subgroups but not others. \n",
    "- What features may have unequal distributions between different subgroups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CODE (1 Line) #\n",
    "# Choose features and metric to use for your model (1 Line)\n",
    "selectedFeatures = [\n",
    "    \"GPA\", \"Educational Prestige\", \"Technical Aptitude\" # Currently used as a placeholder.\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a Metric:  Some key considerations...\n",
    "- Is the metric's value distribution equal among the different groups? \n",
    "- Could some \"linear combination\" of the metrics be more predictive or meaningful to you?\n",
    "- Should your metric include non-performance related features like GPA, or cultural fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pre-existing or make your own metric! (1 Line)\n",
    "metric = \"Avg Deals Closed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick a Label Generation Method: Here we've chosen a metric to use as part of our model training. If you're planning on using a regression technique then you can skip this method as you'll be directly training to predict the metric score. However, if you're using a classification algorithm then you need to bucket the employees in some way. \n",
    "\n",
    "Some considerations...\n",
    "- Does my label generation method make me vulnerable to false positives? false negatives?\n",
    "- How will my resulting labels be used to make the actual decision when it comes to candidates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Label Generation Method (3-5 Lines) #\n",
    "\n",
    "# assignLabelsByPercentile - is a function labelling the dataset by taking the metric scores of the individuals \n",
    "# in the dataset and splitting them into ranked percentile ranges (top Xth percent, next Xth percent, etc.)\n",
    "# @params - \n",
    "#.  dataset is a dataframe of individuals\n",
    "#.  metric - is the feature value we want to rank then divide individuals by\n",
    "# @returns - \n",
    "#.  dataset with labels. \n",
    "def assignLabelsByPercentile(employees, metric, percentile):\n",
    "    employees_labelled = employees.copy()\n",
    "    employees_labelled = employees_labelled.sort_values([metric], ascending=False)\n",
    "    nths = math.floor(len(employees_labelled) / percentile)\n",
    "    num = percentile - 1\n",
    "    labels = []\n",
    "    for x in range(percentile):\n",
    "        for y in range(nths):\n",
    "            labels.append(num)\n",
    "        num -= 1\n",
    "    while (len(labels) != len(employees)):\n",
    "        labels.append(np.random.choice(percentile))\n",
    "    employees_labelled[\"Label\"] = labels\n",
    "    employees_labelled = employees_labelled.sample(frac=1).reset_index(drop=True)\n",
    "    return employees_labelled \n",
    "\n",
    "employees_labelled = assignLabelsByPercentile(employees_processed, metric, 5) # Assigning labels by quintiles of metric\n",
    "# Insert Label Generation Method (3-5 Lines) #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulating your Dataset: Due to bias, or the relative importance of some features you saw in the last exercises, your team may want to meaningfully manipulate features in the dataset some way.  \n",
    "\n",
    "#### For example, you may want to transform certain features in some manner. You may want to remove a subset of the data because it is somehow causing poorer performance due to its outlying nature or you want to rectify some imbalance in the data. Or out of various concerns, you might think that \"tampering\" with the data is just wrong! All for you legal engineers to decide.\n",
    "\n",
    "Some key considerations - \n",
    "- Will my manipulations applied mitigate or accentuate existing biases in the data?\n",
    "- How will my adjustments affect not just the bias but the actual model's performance?\n",
    "- Do I risk overfitting the model by the way I'm thinking about certain candidates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove/alter data points or features # (0-5 Lines)\n",
    "\n",
    "# Remove/alter data points or features #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform, scale, & adjust the data (0-10 Lines)\n",
    "\n",
    "# transformDatapointsToScale - normalizes the features in the dataset matching with features passed in via selectedFeatures.\n",
    "# This is done by dividing each of the chosen columns by that columns' max.\n",
    "# @params:\n",
    "#    - dataset is a dataframe containing individuals (employees or candidates)\n",
    "#    - selectedFeatures is an array of strings, where each string is a feature in the df we seek to normalize\n",
    "# @returns:\n",
    "#    - the dataframe w. selectedFeature's normalized.\n",
    "def transformDatapointsToScale(dataset, selectedFeatures):\n",
    "    df = dataset.copy()\n",
    "    for feature in selectedFeatures:\n",
    "        maximum = df[feature].max()\n",
    "        df[feature] = df[feature].apply(lambda x: x / maximum)\n",
    "    return df\n",
    "\n",
    "#MinMax Normalization Option\n",
    "def rescaling(X):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X)\n",
    "    data = scaler.transform(X)\n",
    "    return data\n",
    "\n",
    "X = transformDatapointsToScale(employees_labelled[selectedFeatures].copy(), selectedFeatures) # Normalizing features by dividing by max\n",
    "y = employees_labelled[\"Label\"]  \n",
    "# Transform, scale, & adjust the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell #\n",
    "# Split into train, test ... #\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=50)\n",
    "# Run this cell #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Picking a model to deploy\n",
    "\n",
    "Ok now that you've been able to experiment with a model, and gained understanding of its architecture, its performance, its advantages and disadvantages. You and your team are now going to settle on a particular model to elect candidates for the next round of hires!\n",
    "\n",
    "You are free to choose any of the architectures including the naive ranking and nearest neighbor models from Milestone 1 as your model as well as any of the ones we have covered here. If your team is already comfortable with the models covered, you are freee to use another model architecture that you're team wants to test.  \n",
    "\n",
    "Just know that you will have to answer a number of questions about its use and performance in the following sections.\n",
    "\n",
    "Some key considerations ...\n",
    "- How will my model interact with the decisions I've made about features. \n",
    "- Can our team explain why the model is coming to the predictions it is coming to?\n",
    "- What's the performance? (Task 3)\n",
    "- Are there any hyperparameters that you can test different values with for this model? If so, what are they and how might they affect your score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT MODEL ARCHITECTURE # (1 Line)\n",
    "model = OneVsRestClassifier(LogisticRegression(random_state = 0, max_iter=500)) #Initialize the model\n",
    "# INSERT MODEL ARCHITECTURE #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Running & Analyzing Initial Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1749, 4: 1850, 2: 1256, 3: 1336, 1: 1309}\n",
      "The accuracy of our model on the data is:  0.8290666666666666\n",
      "The precision of our model on the data is:  0.8289751877322207\n",
      "The recall of our model on the data is:  0.829478820829441\n"
     ]
    }
   ],
   "source": [
    "# RUN THIS CELL (0 Lines) #\n",
    "logreg_model = model.fit(X_train, y_train) #Train the model\n",
    "getModelStats(logreg_model, X_train, y_train) #Get initial model performance\n",
    "# RUN THIS CELL #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Analyzing Fairness of the Model\n",
    "Here we'd like you to apply some of the concepts and fairness notions we gave to you in the last exercise to make a determination of the model's equity in its predictions. No rigorous examination is required but you should try to calculate some of the metrics introduced among the different subgroups for your model...\n",
    "\n",
    "- We've given an example of what one simple approach might be below - examining the accuracy of the model on different subgroups.\n",
    "\n",
    "Key Considerations ...\n",
    "- Is there a potential differential validity problem present? (Hint: Check weights if utilizing regressions)\n",
    "- Is my model more susceptible to false positives or false negatives - how can I illustrate that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats are for following class:  African-American\n",
      "{4: 2416, 2: 1667, 3: 1776, 1: 1767, 0: 2374}\n",
      "The accuracy of our model on the data is:  0.8305\n",
      "The precision of our model on the data is:  0.8305\n",
      "The recall of our model on the data is:  0.8309698091751491\n",
      "\n",
      "Stats are for following class:  Caucasian\n",
      "{4: 2416, 2: 1667, 3: 1776, 1: 1767, 0: 2374}\n",
      "The accuracy of our model on the data is:  0.8305\n",
      "The precision of our model on the data is:  0.8305\n",
      "The recall of our model on the data is:  0.8309698091751491\n",
      "\n",
      "Stats are for following class:  Hispanic\n",
      "{4: 2416, 2: 1667, 3: 1776, 1: 1767, 0: 2374}\n",
      "The accuracy of our model on the data is:  0.8305\n",
      "The precision of our model on the data is:  0.8305\n",
      "The recall of our model on the data is:  0.8309698091751491\n",
      "\n",
      "Stats are for following class:  Other\n",
      "{4: 2416, 2: 1667, 3: 1776, 1: 1767, 0: 2374}\n",
      "The accuracy of our model on the data is:  0.8305\n",
      "The precision of our model on the data is:  0.8305\n",
      "The recall of our model on the data is:  0.8309698091751491\n",
      "\n",
      "Stats are for following class:  Asian\n",
      "{4: 2416, 2: 1667, 3: 1776, 1: 1767, 0: 2374}\n",
      "The accuracy of our model on the data is:  0.8305\n",
      "The precision of our model on the data is:  0.8305\n",
      "The recall of our model on the data is:  0.8309698091751491\n",
      "\n",
      "{0: array([ -0.40264421,   0.19954788, -21.15957461]), 1: array([ 0.23625017,  0.06497519, -2.5625832 ]), 2: array([ 0.41302228, -0.03384057, -0.06395019]), 3: array([-0.32629888,  0.08375403,  2.43818714]), 4: array([ 0.08621905, -0.11358033, 21.38676069])}\n"
     ]
    }
   ],
   "source": [
    "# INSERT Fairness Metrics # (3-10 Lines)\n",
    "\n",
    "# Checking the accuracy amongst distinct groups\n",
    "races = [\"African-American\", \"Caucasian\", \"Hispanic\", \"Other\", \"Asian\"]\n",
    "for race in races:\n",
    "    print(\"Stats are for following class: \", race)\n",
    "    x_class = transformDatapointsToScale(employees_labelled, selectedFeatures)\n",
    "    y_class = x_class[\"Label\"]\n",
    "    x_class = x_class[selectedFeatures].copy()\n",
    "    getModelStats(logreg_model, x_class, y_class)\n",
    "    print(\"\")\n",
    "    \n",
    "    \n",
    "# Examining the model weights in the model per class....\n",
    "coeff_values = list(logreg_model.coef_)\n",
    "features = list(logreg_model.classes_)\n",
    "assert(len(coeff_values) == len(features))\n",
    "featureToValues = {features[x] : coeff_values[x] for x in range(len(features))}\n",
    "print(featureToValues)\n",
    "    \n",
    "# INSERT # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Deploying on Candidates!\n",
    "- Alright we've finally gotten to where your team can use the model you've built on the candidate dataset and see the results. Before we run it though, recall there's one last major step. Choosing a selection method. If you decided on a classification algorithm you may have decided that candidates assigned the best label are those selected for the next round. But that's not the only way to do things. Be as creative as you'd like to be!\n",
    "\n",
    "Key Considerations ...\n",
    "- What was the label generation method you chose, what labels are therefore most predictive of performance. \n",
    "- Is the selection method to narrow? to general?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL (1-3 Lines) #\n",
    "X_candidates = transformDatapointsToScale(candidates_processed[selectedFeatures].copy(), selectedFeatures)\n",
    "candidate_labels = logreg_model.predict(X_candidates)\n",
    "# RUN THIS CELL #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT Selection Method # (3-10 Lines)\n",
    "def classificationSelection(candidates, labels, acceptValue):\n",
    "    df = candidates.copy()\n",
    "    df[\"Labels\"] = labels\n",
    "    candidatesSelected = df[df[\"Labels\"].isin([acceptValue])]\n",
    "    return candidatesSelected\n",
    "\n",
    "candidatesSelected = classificationSelection(candidates_processed, candidate_labels, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally! Time to give it a shot on the dataset and we'll see how we do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selection rate for Caucasians:  0.25672727272727275\n",
      "The selection rate for Asians:  0.26666666666666666\n",
      "The selection rate for African-Americans:  0.24\n",
      "The selection rate for Hispanics:  0.22\n",
      "The selection rate for Other Races:  0.30666666666666664\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run This Cell (1-3 Lines) #\n",
    "graphSelectionRates(candidatesSelected, candidates_processed, \"race\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Iterate!\n",
    "\n",
    "So, you may be ecstatic or baffled with your results. Either way, the point now is to try and iteratively improve your approach so that your team is satisfied with the model's performance or thinks they can justify their decisions and the model's behavior. Now that you made your first way through, take the time to think about changing your data engineering process, model architecture, selection methods, etc. to try and improve results. Recall that \"improving\" can mean different things for different folks based on your priorities. For some that will mean enhancing the accuracy of the model on the employees. For others it will be rectifying the disparate outcomes on the candidate dataset. Some will need to narrow their selection rate overall, ohers will need to widen it. \n",
    "\n",
    "Your team may not arrive at an approach you are wholly satisfied with - that's totally alright! Sometimes these problems can seem or even be intractable. Nonetheless, along each of these tasks (1-5), unless you're perfectly happy with the results, you should try at least one to two changes per stage and see what effect it has. You'll need to discuss that experimentation in this final task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Task: Memo Write-up\n",
    "\n",
    "Alright time to finally put your writing cap back on.  Now that you've come to an approach you're satisfied with (or settled on), the GC\"s office wants a ~2 page write-up of your approach, its advantages, disadvantages, threats of statutory liability, and defenses you should lay out the memo in the following manner.\n",
    "\n",
    "Memo Outline & Additional Questions....\n",
    "\n",
    "Outline Guide to the Memo\n",
    "\n",
    "- Describe your team's model, the architecture, selected features, and data steps.\n",
    "    - What are some advantages or benefical \"features\" of your overall approach?\n",
    "    - What are some disadvantages or risks with your approach?\n",
    "- Data Handling\n",
    "    - Starting with Data Engineering, describe how your team decided on the features, performance measure, and label generation method that you ended up with.\n",
    "    - How did you go about making your decisions?\n",
    "- Model Choice\n",
    "    - How did your team choose a model? Why did you choose what you did over the other approached we covered?\n",
    "    - What were the main decision factors (performance? explainability?)? Were there hyper-parameters that you tweaked?\n",
    "- Performance - State the model's performance on the test set\n",
    "    - Accuracy, precision, recall.\n",
    "    - Also the model's fairness (using the metrics you used).\n",
    "    - What were your measures on your team's first iteration? How did you go about trying to improve it to what it is now?\n",
    "- For candidate selection\n",
    "    - How were candidates ultimately selected? How did you choose this selection method?\n",
    "    - Was there a disparate impact? If so, discuss the validity of a business necessity-type defense given your approach.\n",
    "- Race Aware Corrections -\n",
    "    - In your attempt to improve the model performance or rectify some bias/differential validity problem did you enlist any \"Race-Aware\" Corrections?\n",
    "    - Are those corrections lawful under the Ricci v. Weber case and the covered case law we reviewed on Affirmative Action Programs?\n",
    "\n",
    "**Additional Hypothetical Questions:**\n",
    "\n",
    "1. Suppose manager's assessment score and the average commute time were heavily biased against minorities leaving only average deals closed, left. But suppose again that average deals closed was a highly noisy feature. A number of the recorded values were inaccurate, or altogether missing for the employees. How would you address the situation.\n",
    "2. In this case, the Supreme Court rejected a “bottom line” defense in which a defendant tried to justify a preliminary screening test with a significant disparate impact by arguing that the selection process ultimately selected protected candidates at a higher rate. Look deeper into the holding and report how your team believes this effects lawyers and engineers trying to develop automated hiring systems.\n",
    "3. Suppose your model was built such that given the current employee dataset, there was not a clear 4/5s violation in the candidate selection rates but there still existed a ~15 percent disparity between a minority group and the highest performing group.  One suggestion is to seek to gather more data on past employees to have the model train on and improve from, but this can be a costly process both in dollars and time.  How would your team go about trying to decide on a course of action? What context is key?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
